{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from shapely.affinity import scale\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "from pygbif.species import name_backbone\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "file_dir=('/Users/maddie/Projects/CPSC_597/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframes to be concatenated and filtered\n",
    "occ_all_species = pd.read_csv(file_dir+\"/data_raw/gbif_data_raw/occurrences_all_species.csv\", low_memory= False)\n",
    "df = occ_all_species[occ_all_species['label'].str.contains(\" \")]\n",
    "\n",
    "#Get unique label names\n",
    "unique_labels=df[\"label\"].unique()\n",
    "\n",
    "names = []\n",
    "back_key =[]\n",
    "remaining_labels=[]\n",
    "\n",
    "#Get backbone associated species names and taxon keys\n",
    "for item in unique_labels:\n",
    "    if \"species\" in name_backbone(item):\n",
    "        i = name_backbone(item)['species']\n",
    "        j = name_backbone(item)['speciesKey']\n",
    "        names.append(i)\n",
    "        back_key.append(j)\n",
    "    else:\n",
    "        remaining_labels.append(item)\n",
    "        \n",
    "for item in remaining_labels:\n",
    "    value=name_backbone(item)['taxonKey']\n",
    "    back_key.append(value)\n",
    "    names.append(item)\n",
    "    \n",
    "#Put into DataFrame\n",
    "df=pd.DataFrame({\"label\": unique_labels,\"back_key\": back_key,\"species\": names},columns=[\"label\",\"back_key\",\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2 without na's n.rows: 250264\n"
     ]
    }
   ],
   "source": [
    "#Concatenate with occurrence data, dataframe, drop na's \n",
    "df2=pd.merge(occ_all_species,df,how=\"left\",on=\"label\")\n",
    "\n",
    "df2 = df2[pd.notnull(df2['species_x'])]\n",
    "df2 = df2[pd.notnull(df2['decimalLatitude'])]\n",
    "df2 = df2[pd.notnull(df2['decimalLongitude'])]\n",
    "\n",
    "print(\"df2 without na's n.rows:\", len(df2.index))\n",
    "\n",
    "df2[\"back_key\"]=df2[\"back_key\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citharichthys_sordidus 31634\n",
      "Engraulis_mordax 24710\n",
      "Paralichthys_californicus 5340\n",
      "Scomber_japonicus 20855\n",
      "Thunnus_alalunga 35567\n",
      "Xiphias_gladius 132158\n"
     ]
    }
   ],
   "source": [
    "#list of species\n",
    "species = df2[\"species_x\"].unique()\n",
    "species.sort()\n",
    "\n",
    "#save separate dataframe for each species as csv file \n",
    "for spec in species:\n",
    "    data=df2.loc[df2['species_x'] == spec]\n",
    "    if len(data.index)>= 10:\n",
    "        spec=spec.replace(\" \",\"_\")\n",
    "        print(\"%s\"%spec, len(data.index))\n",
    "        data.to_csv(file_dir+'/data_raw/gbif_data_raw/%s_gbif_raw.csv'%spec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
