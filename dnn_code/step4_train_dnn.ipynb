{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d337534-4b82-414a-aaad-98fc495ce741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 17:42:26.727255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import shap\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import regularizers\n",
    "\n",
    "    \n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eebb65e-954d-4f38-a8b8-60d8627f46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir=('/Users/maddie/Projects/CPSC_597')\n",
    "#create text file to store results in and close again:\n",
    "with open(file_dir+'/results/DNN_performance/DNN_eval.txt','w+') as file:\n",
    "    file.write(\"Species\"+\"\\t\"+\"Test_loss\"+\"\\t\"+\"Test_acc\"+\"\\t\"+\"Test_tpr\"+\"\\t\"+\"Test_AUC\"+\"\\t\"+\"Test_LCI95%\"+\"\\t\"+\"Test_UCI95%\"+\"\\t\"+\"occ_samples\"+\"\\t\"+\"abs_samples\"+\"\\n\")\n",
    "    file.close()\n",
    "#access file with list of taxa names\n",
    "taxa=pd.read_csv(file_dir+'/data/modified_data/gbif_filtered/taxa_list.txt',header=None)\n",
    "taxa.columns=[\"taxon\"] \n",
    "\n",
    "###column variable names\n",
    "with open(file_dir+'/data/data_raw/bio_oracle/variable_list.txt') as f:\n",
    "      new_cols = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d53731-4b59-46b2-ad16-72bcee4abd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "159/159 [==============================] - 0s 739us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "159/159 [==============================] - 0s 618us/step\n",
      "run 2\n",
      "159/159 [==============================] - 0s 749us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "159/159 [==============================] - 0s 614us/step\n",
      "run 3\n",
      "159/159 [==============================] - 0s 748us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "159/159 [==============================] - 0s 625us/step\n",
      "run 4\n",
      "159/159 [==============================] - 0s 756us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "159/159 [==============================] - 0s 635us/step\n",
      "run 5\n",
      "159/159 [==============================] - 0s 753us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "159/159 [==============================] - 0s 623us/step\n",
      "run 1\n",
      "237/237 [==============================] - 0s 756us/step - loss: 5.5844e-06 - accuracy: 1.0000\n",
      "237/237 [==============================] - 0s 609us/step\n",
      "run 2\n",
      "237/237 [==============================] - 0s 736us/step - loss: 9.8561e-05 - accuracy: 1.0000\n",
      "237/237 [==============================] - 0s 718us/step\n",
      "run 3\n",
      "237/237 [==============================] - 0s 745us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "237/237 [==============================] - 0s 616us/step\n",
      "run 4\n",
      "237/237 [==============================] - 0s 763us/step - loss: 3.6779e-05 - accuracy: 1.0000\n",
      "237/237 [==============================] - 0s 616us/step\n",
      "run 5\n",
      "237/237 [==============================] - 0s 759us/step - loss: 9.6491e-05 - accuracy: 1.0000\n",
      "237/237 [==============================] - 0s 632us/step\n",
      "run 1\n",
      "198/198 [==============================] - 0s 777us/step - loss: 5.3655e-04 - accuracy: 1.0000\n",
      "198/198 [==============================] - 0s 627us/step\n",
      "run 2\n",
      "198/198 [==============================] - 0s 754us/step - loss: 0.2598 - accuracy: 0.9276\n",
      "198/198 [==============================] - 0s 625us/step\n",
      "run 3\n",
      "198/198 [==============================] - 0s 754us/step - loss: 5.1861e-05 - accuracy: 1.0000\n",
      "198/198 [==============================] - 0s 626us/step\n",
      "run 4\n",
      "198/198 [==============================] - 0s 751us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "198/198 [==============================] - 0s 632us/step\n",
      "run 5\n",
      "198/198 [==============================] - 0s 805us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "198/198 [==============================] - 0s 661us/step\n",
      "run 1\n",
      "145/145 [==============================] - 0s 817us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "145/145 [==============================] - 0s 822us/step\n",
      "run 2\n",
      "145/145 [==============================] - 0s 845us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "145/145 [==============================] - 0s 650us/step\n",
      "run 3\n",
      "145/145 [==============================] - 0s 790us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "145/145 [==============================] - 0s 645us/step\n",
      "run 4\n",
      "145/145 [==============================] - 0s 783us/step - loss: 1.5314e-04 - accuracy: 1.0000\n",
      "145/145 [==============================] - 0s 669us/step\n",
      "run 5\n",
      "145/145 [==============================] - 0s 800us/step - loss: 1.6323e-04 - accuracy: 1.0000\n",
      "145/145 [==============================] - 0s 629us/step\n",
      "run 1\n",
      "291/291 [==============================] - 0s 751us/step - loss: 0.5509 - accuracy: 0.7602\n",
      "291/291 [==============================] - 0s 637us/step\n",
      "run 2\n",
      "291/291 [==============================] - 0s 752us/step - loss: 0.5509 - accuracy: 0.7602\n",
      "291/291 [==============================] - 0s 614us/step\n",
      "run 3\n",
      "291/291 [==============================] - 0s 766us/step - loss: 0.5509 - accuracy: 0.7602\n",
      "291/291 [==============================] - 0s 620us/step\n",
      "run 4\n",
      "291/291 [==============================] - 0s 754us/step - loss: 0.5509 - accuracy: 0.7602\n",
      "291/291 [==============================] - 0s 618us/step\n",
      "run 5\n",
      "291/291 [==============================] - 0s 746us/step - loss: 0.5509 - accuracy: 0.7602\n",
      "291/291 [==============================] - 0s 620us/step\n",
      "run 1\n",
      "370/370 [==============================] - 0s 747us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "370/370 [==============================] - 0s 617us/step\n",
      "run 2\n",
      "370/370 [==============================] - 0s 745us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "370/370 [==============================] - 0s 614us/step\n",
      "run 3\n",
      "370/370 [==============================] - 0s 739us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "370/370 [==============================] - 0s 619us/step\n",
      "run 4\n",
      "370/370 [==============================] - 0s 731us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "370/370 [==============================] - 0s 611us/step\n",
      "run 5\n",
      "370/370 [==============================] - 0s 749us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "370/370 [==============================] - 0s 659us/step\n"
     ]
    }
   ],
   "source": [
    "var_names=[]\n",
    "for item in new_cols:\n",
    "    item=item.replace(\"\\n\",\"\")\n",
    "    var_names.append(item) \n",
    "for species in taxa[\"taxon\"][:]:\n",
    "   \n",
    "    #open dataframe and rename columns\n",
    "    spec = species\n",
    "    table = pd.read_csv(file_dir +\"/data/modified_data/spec_ppa_env/%s_env_dataframe.csv\"%spec)         \n",
    "    table.rename(columns=dict(zip(table.columns[1:9], var_names)),inplace=True)\n",
    "    \n",
    "    ####################################\n",
    "    #  filter dataframe for training   #\n",
    "    ####################################\n",
    "   \n",
    "    # drop any row with no-data values\n",
    "    table = table.dropna(axis=0, how=\"any\")\n",
    "\n",
    "\n",
    "    # make feature vector\n",
    "    band_columns = [column for column in table.columns[1:9]]\n",
    "    \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in table.iterrows():\n",
    "        x = row[band_columns].values\n",
    "        x = x.tolist()\n",
    "        x.append(row[\"present/pseudo_absent\"])\n",
    "        X.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data=X, columns=band_columns + [\"presence\"])\n",
    "    df.to_csv(\"filtered.csv\", index=None)\n",
    "\n",
    "    # extract n. of occ. and abs. samples\n",
    "    occ_len=int(len(df[df[\"presence\" ]==1]))\n",
    "    abs_len=int(len(df[df[\"presence\" ]==0]))\n",
    "    \n",
    "    ####################################\n",
    "    #  Numpy feature and target array  #\n",
    "    ####################################\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    band_columns = [column for column in df.columns[:-1]]\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(row[band_columns].values.tolist())\n",
    "        y.append([1 - row[\"presence\"], row[\"presence\"]])\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    y = np.vstack(y)\n",
    "\n",
    "    ####################################\n",
    "    #    Split training and test set   #\n",
    "    ####################################\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y,random_state=42)\n",
    "    \n",
    "    test_set=pd.DataFrame(X_test)\n",
    "    test_set.rename(columns=dict(zip(test_set.columns[0:8], var_names)),inplace=True)\n",
    "    \n",
    "    shuffled_X_train=X_train.copy()\n",
    "    np.random.shuffle(shuffled_X_train)\n",
    "    #shuffled_X_train=shuffled_X_train[:1000] # random subsample from test set for feature importance\n",
    "    \n",
    "    shuffled_X_test=X_test.copy()\n",
    "    np.random.shuffle(shuffled_X_test)\n",
    "    #shuffled_X_test=shuffled_X_test[:1000] # random subsample from test set for feature importance\n",
    "    \n",
    "    ####################################\n",
    "    #      Training and testing        #\n",
    "    ####################################\n",
    "    \n",
    "    # prepare metrics\n",
    "    test_loss=[]\n",
    "    test_acc=[]\n",
    "    test_AUC=[]\n",
    "    test_tpr=[]\n",
    "    test_uci=[]\n",
    "    test_lci=[]\n",
    "\n",
    "   \n",
    "    Best_model_AUC=[0]\n",
    "    \n",
    "    # Five repetitions\n",
    "    for i in range(1,6):\n",
    "        print(\"run %s\"%i)\n",
    "        ###################\n",
    "        # Construct model #\n",
    "        ###################\n",
    "        batch_size = 75\n",
    "        num_classes = 2\n",
    "        epochs = 40\n",
    "\n",
    "        num_inputs = X.shape[1]  # number of features\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        layer_1 = Dense(50, activation='relu',input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.000001))\n",
    "        layer_2 = Dense(25, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.000001))\n",
    "        layer_3 = Dense(25, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.0000001))\n",
    "        layer_4 = Dense(25, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.00000001))\n",
    "\n",
    "\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(layer_2)\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(layer_3)\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(layer_4)\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "        out_layer = Dense(num_classes, activation=None)\n",
    "        model.add(out_layer)\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics =['accuracy'])\n",
    "        \n",
    "        ###############\n",
    "        # Train model #\n",
    "        ###############\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, verbose=0)\n",
    "\n",
    "        ##############\n",
    "        # Test model #\n",
    "        ##############\n",
    "        score = model.evaluate(X_test, y_test, verbose=1)\n",
    "        predictions = model.predict(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:, 1], predictions[:, 1])\n",
    "        len_tpr=int(len(tpr)/2)\n",
    "      \n",
    "\n",
    "        #################\n",
    "        # Append scores #\n",
    "        #################\n",
    "        test_loss.append(score[0])\n",
    "        test_acc.append(score[1])\n",
    "        test_AUC.append(roc_auc_score(y_test[:, 1], predictions[:, 1]))\n",
    "        test_tpr.append(tpr[len_tpr])\n",
    "        AUC = roc_auc_score(y_test[:, 1], predictions[:, 1])\n",
    "\n",
    "        ###############################\n",
    "        # Create confidence intervals #\n",
    "        ###############################\n",
    "        n_bootstraps=1000\n",
    "        y_pred=predictions[:,1]\n",
    "        y_true=y_test[:,1]\n",
    "        rng_seed=42\n",
    "        bootstrapped_scores =[]\n",
    "\n",
    "\n",
    "        rng=np.random.RandomState(rng_seed)\n",
    "        for i in range (n_bootstraps):\n",
    "            #bootstrap by sampling with replacement on prediction indices\n",
    "            indices = rng.randint(0,len(y_pred)-1,len(y_pred))\n",
    "            if len (np.unique(y_true[indices])) <2:\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices],y_pred[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "\n",
    "        sorted_scores=np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        ci_lower=sorted_scores[int(0.05*len(sorted_scores))]\n",
    "        ci_upper=sorted_scores[int(0.95*len(sorted_scores))]\n",
    "     \n",
    "        test_lci.append(ci_lower)\n",
    "        test_uci.append(ci_upper)\n",
    "       \n",
    "    \n",
    "        ##############################################################\n",
    "        # Selection of best model across runs and feature importance #\n",
    "        ##############################################################\n",
    "    \n",
    "        #determine whether new model AUC is higher\n",
    "        if AUC > Best_model_AUC[0]:\n",
    "            # if yes save model to disk / overwrite previous model\n",
    "            Best_model_AUC[0]=AUC\n",
    "            model_json=model.to_json()\n",
    "            with open (file_dir+'/results/fish/{}/{}_model.json'.format(spec,spec),'w') as json_file:\n",
    "                json_file.write(model_json)\n",
    "            model.save_weights(file_dir+'/results/fish/{}/{}_model.h5'.format(spec,spec))\n",
    "            #if yes, save a figure of shap feature value impact    \n",
    "            \n",
    "           # if int(len(X_train)) > 5000:           \n",
    "           #     explainer=shap.DeepExplainer(model,shuffled_X_train)\n",
    "           #     test_set=pd.DataFrame(shuffled_X_test)\n",
    "           #     test_set.rename(columns=dict(zip(test_set.columns[0:40], var_names)),inplace=True)\n",
    "                \n",
    "           #     shap_values=explainer.shap_values(shuffled_X_test)\n",
    "           #     fig=shap.summary_plot(shap_values[1],test_set,show=False)\n",
    "           #     plt.savefig(file_dir+'/results/fish/{}/{}_feature_impact'.format(spec,spec),bbox_inches=\"tight\")\n",
    "           #     plt.close()\n",
    "            \n",
    "           # else:\n",
    "           #     explainer=shap.DeepExplainer(model,X_train)\n",
    "           #     shap_values=explainer.shap_values(X_test)\n",
    "           #     fig=shap.summary_plot(shap_values[1],test_set,show=False)\n",
    "           #     plt.savefig(file_dir+'/results/fish/{}/{}_feature_impact'.format(spec,spec),bbox_inches=\"tight\")\n",
    "           #     plt.close()\n",
    "            \n",
    "\n",
    "\n",
    "    # Model output metrics averaged across five runs to be written to file\n",
    "    avg_loss= sum(test_loss)/len(test_loss)\n",
    "    avg_acc = sum(test_acc)/len(test_acc)\n",
    "    avg_AUC = sum(test_AUC)/len(test_AUC)\n",
    "    avg_tpr = sum(test_tpr)/len(test_tpr)\n",
    "    avg_lci = sum(test_lci)/len(test_lci)\n",
    "    avg_uci = sum(test_uci)/len(test_uci)\n",
    "\n",
    "    # Write to file\n",
    "    with open(file_dir+'/results/DNN_performance/DNN_eval.txt','a') as file:\n",
    "        file.write(spec+\"\\t\"+str(avg_loss)+\"\\t\"+str(avg_acc)+\"\\t\"+str(avg_tpr)+\"\\t\"+str(avg_AUC)+\"\\t\"+str(avg_lci)+\"\\t\"+str(avg_uci)+\"\\t\"+str(occ_len)+\"\\t\"+str(abs_len)+\"\\n\")       \n",
    "\n",
    "\n",
    "    #Next species!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a265a4-989c-4ba5-8151-c98b94ad6efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629f72c-1835-46a2-8b2a-c115fe1f63b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
